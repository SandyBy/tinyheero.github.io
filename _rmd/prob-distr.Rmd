---
title: "What is a Probability Distribution?"
layout: post
output: 
  html_document:
tags: []
---

```{r echo = FALSE}
library("knitr")
library("captioner")
library("magrittr")
library("captioner")
#knitr::opts_chunk$set(fig.path="{{ site.url }}/assets/gmm-em/")

fig_nums <- captioner(prefix = "<u>Figure</u>", css_class = "figcaption")
```

A probability distribution is a way to represent the possible values and the respective probabilities of a random variable. There are two types of probability distributions: discrete and continuous probability distribution. As you might guess, a discrete probability distribution is used when we have a discrete random variable. A continuous probability distribution is used when we have a continuous random variable. 

**Table of Contents**

<ul data-toc="body" data-toc-headings="h2,h3"></ul>

## Example of a Discrete Probability Distribution

In a previous post on [random variables]({% post_url 2016-02-26-random-variables %}), I had used the example of a random process of flipping a coin x number of times and measuring the total of heads using a discrete random variable Y. As an example, let us try to build a probability distribution from a random process like this where we are flipping a coin 3 times. This random process can have a total of 8 possible outcomes:

<div class="alert alert-dismissible alert-warning">
<h4>Heads Up!</h4>
[I suggest watching this video](https://www.youtube.com/watch?v=5lpqiGixDd0) if you are unclear on how these outcomes were generated.
</div>

1. HHH
1. HHT
1. HTH
1. HTT
1. THH
1. THT
1. TTH
1. TTT

We let our random variable Y serve as a way to map the number of heads we get to a numeric value. So the most initutive way would be:

1. Y = 0 if we get no heads.
1. Y = 1 if we get 1 head.
1. Y = 2 if we get 2 heads.
1. Y = 3 if we get 3 heads.

So now that we have this random variable and the possible values this variable can take, let's try to figure out the associated probabilities of each outcome. 

1. <span class="inlinecode">$P(Y = 0)$</span>: The only way we can get 0 heads is if all 3 coin flips gives a tail. The only outcome that satisfies this is the TTT outcome. This means the probability P(Y = 0) = 1/8.
1. <span class="inlinecode">$P(Y = 1)$</span>: To get 1 head, the outcomes HTT, THT, and TTH satisfy this. So this means 3/8.
1. <span class="inlinecode">$P(Y = 2)$</span>: To get 2 heads, the outcomes HHT, HTH, and THH satisfy this. So this means 3/8.
1. <span class="inlinecode">$P(Y = 3)$</span>: The only way we can get 3 heads is if all 3 coin flips gives a head The only outcome that satisfies this is the TTT outcome. This means the probability P(Y = 3) = 1/8.
   
With these values and probabilites, we can visualize our probability distribution like this:

```{r prob_distr_example, warning = FALSE, message = FALSE}
library("ggplot2")
library("dplyr")

prob.distr.df <- data_frame(value = c(0, 1, 2, 3),
                            prob = c(1/8, 3/8, 3/8, 1/8))

prob.distr.df %>%
  ggplot(aes(x = value, y = prob)) +
  geom_bar(stat = "identity") +
  ylim(c(0, 1)) +
  xlab("Y (Number of Heads)") + 
  ylab("Probability")
```

`r fig_nums("prob_distr_example.fig.cap", "Probability Distribution of Random Variable Y. The x-axes shows the different outcomes of the random variable while the y-axes shows the corresponding probabilities of these outcomes.")`

## Example of a Continuous Probability Distribution

In the example above, Y was a discrete random variable. When the outcomes are discrete we have the ability to directly measure the probability of each outcome. Any probability distributions based on a discrete random variable is classified as a "discrete probability distribution" (which is what `r fig_nums("prob_distr_example.fig.cap", display = "cite")` is).

When the random variable is continuous, then things get a little more complicated. **We are not able to directly measure the probability of a specific continuous value**. This may seem a big confusing at first, but imagine you had a random variable X that measured the price of a diamond. 

To make this more concrete, we will use the diamond dataset from ggplot2 to illustrate this example. First let's plot the histogram of diamond prices of 53940 diamonds:

```{r, warning = FALSE, message = FALSE}
library("dplyr")
library("ggplot2")

diamonds %>%
  ggplot(aes(x = price)) +
  geom_histogram() +
  xlab("X (Diamond Price)")
```

Imagine you were asked you the following question: If you sampled a single diamond, what is the probability that its **exact** price is \$326.57? Not \$326.58 or \$326.56, but exactly \$326.57? 

If you think of it that way, then the probability of getting a diamond with that exact price is probably really low. In fact, the probability of any exact price is really low. **This is why the concept of probability in the continous scale doesn't make sense**. Instead, what we do is "discretize" the sample space. For instance, we can "discretize" the prices into bins of size \$100:

```{r, warning = FALSE, message = FALSE}
diamonds %>%
  ggplot(aes(x = price)) +
  geom_histogram(binwidth = 100) +
  xlab("X (Diamond Price)") +
  ylab("Number of Diamonds")
```

Once we have these bins of data, we can start talking about proportion of samples falling into bins. For instance, we can ask the question what is the probability of a diamond having a price between 1000 and 1100:

```{r}
num.diamonds.in.bin <- 
  diamonds %>%
  filter(price > 1000, price < 1100) %>%
  nrow()
```

A total of `r num.diamonds.in.bin` diamonds fall in this bin which equates to a probability of:

```{r}
prob.mass <- num.diamonds.in.bin / nrow(diamonds)
prob.mass
```

When we talk about the probability of a discrete outcome falling into a bin like this, then this type of probability is called a "probability mass". As the probability mass is dependent on the bin width, the "probability density" is used to represent the ratio of the probability mass to bin width (interval):

```{r}
prob.dens <- prob.mass / (62 - 60)
prob.dens
```

To get more precision, we would want our intervals to be small since wide intervals are not very informative. Ideally, our intervals should be infinitesimally small. Thankfully we have computers that can perform this calculation for us:

```{r}
diamonds %>%
  ggplot(aes(x = price)) +
  geom_density() +
  xlab("X (Diamond Price)") +
  ylab("Density")
```

This is what is called a "probability density function" (pdf) which is used to describe a continuous probability distribution. Formally, this function takes the form of:


<div>
$$P(a \leq X \leq b) = \int_{a}^{b} f_X(x) dx$$
</div>



The benefit of working with probability density is that we are no longer tied to a bin width. So if we are interested in knowing the probability of getting a diamond between some interval \[A-B]\, then this simply becomes:


# References

* [Doing Bayesian Data Analysis - A Tutorial with R, JAGS, and Stan](https://sites.google.com/site/doingbayesiandataanalysis/)
* [Probability Distribution Table - Intro with tossing a coin 3 times](https://www.youtube.com/watch?v=5lpqiGixDd0)
* [What is a Probability Distribution?](http://stattrek.com/probability-distributions/probability-distribution.aspx)
* [Continuous Probability Distribution](http://stattrek.com/statistics/dictionary.aspx?definition=Continuous%20probability%20distribution)
* [Khan Academy - Probability density function](https://www.youtube.com/watch?v=Fvi9A_tEmXQ)
